import { mastra, validateConfig } from './config/index.js';

async function testSetup() {
  const isDryRun = process.env.DRY_RUN === 'true' || !process.env.OPENAI_API_KEY;
  
  console.log('ğŸ” Validating configuration...');
  
  // Dry-runãƒ¢ãƒ¼ãƒ‰ã§ã¯ç’°å¢ƒå¤‰æ•°ãƒã‚§ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—
  if (isDryRun) {
    console.log('ğŸ“ Running in dry-run mode (no actual API calls)');
    if (!process.env.OPENAI_API_KEY) {
      console.log('âš ï¸  OPENAI_API_KEY not set - would be required for actual execution');
    }
  } else {
    validateConfig();
  }
  console.log('âœ… Configuration valid');
  
  console.log('ğŸ” Testing OpenAI connection...');
  
  if (isDryRun) {
    console.log('ğŸ“ [DRY-RUN] Would call OpenAI API with:');
    console.log('   - Model: gpt-3.5-turbo');
    console.log('   - Prompt: "Say \\"Hello, Mastra!\\""');
    console.log('   - Max tokens: 10');
    console.log('âœ… [DRY-RUN] OpenAI integration configured correctly');
  } else {
    // å®Ÿéš›ã®APIå‘¼ã³å‡ºã—
    try {
      const response = await mastra.providers.openai.generateText({
        model: 'gpt-3.5-turbo',
        prompt: 'Say "Hello, Mastra!"',
        maxTokens: 10,
      });
      console.log('âœ… OpenAI response:', response);
      
      // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã®æ§‹é€ ã‚’ç¢ºèª
      if (response && typeof response === 'object') {
        console.log('ğŸ“Š Response structure verified');
        console.log('   - Type:', typeof response);
        console.log('   - Keys:', Object.keys(response).join(', '));
      }
    } catch (error) {
      console.error('âŒ OpenAI connection failed:', error);
      throw error;
    }
  }
  
  console.log('ğŸ‰ Setup complete!');
  
  // ä½¿ç”¨æ–¹æ³•ã®èª¬æ˜
  console.log('\nğŸ“š Usage:');
  console.log('   Dry-run mode: DRY_RUN=true npx tsx src/mastra/test-setup.ts');
  console.log('   Actual API call: OPENAI_API_KEY=your-key npx tsx src/mastra/test-setup.ts');
}

testSetup().catch(console.error);